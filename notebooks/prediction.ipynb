{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ed1dd554344ddb03c2aed18abc76d867a04f9c65511a7369f0205387d84c0a13"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data prediction\n",
    "\n",
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "source": [
    "## Data preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/DEvideos.csv',\n",
    "    low_memory=False)\n",
    "\n",
    "df['trending_date'] = df.apply(lambda row: datetime.strptime(row['trending_date'], '%y.%d.%m'), axis=1)\n",
    "df['publish_time'] = df.apply(lambda row: datetime.strptime(row['publish_time'], '%Y-%m-%dT%H:%M:%S.000Z'), axis=1)\n",
    "df['days_until_trending'] = df.apply(lambda row: ((row['trending_date'] - row['publish_time']).days + 1), axis=1)\n",
    "\n",
    "df['tags_count'] = df.apply(lambda row: len(row['tags'].split('|')), axis=1)\n",
    "df['publish_hour'] = df['publish_time'].map(lambda x: x.hour)\n",
    "df['publish_month'] = df['publish_time'].map(lambda x: x.month)\n",
    "df['publish_year'] = df['publish_time'].map(lambda x: x.year)\n",
    "df['publish_day_of_month'] = df['publish_time'].map(lambda x: x.day)\n",
    "df['publish_weekday'] = df['publish_time'].map(lambda x: x.weekday()) # 0: Monday, 6: Sunday\n",
    "\n",
    "df['like_dislike_ratio'] = df.apply(lambda row: row['likes'] / (row['dislikes'] + 1), axis=1)\n",
    "df['like_view_ratio'] = df.apply(lambda row: row['likes'] / (row['views'] + 1), axis=1)\n",
    "\n",
    "df['ratings'] = df['likes'] + df['dislikes']\n",
    "df['likes_per_rating'] = df.apply(lambda row: 0 if row['ratings'] == 0 else row['likes'] / row['ratings'], axis=1)\n",
    "df['ratings_per_view'] = df['ratings'] / df['views']\n",
    "df['comments_per_view'] = df['comment_count'] / df['views']\n",
    "\n",
    "# Using int instead of cat\n",
    "def assign_target_category(row):\n",
    "    if row['days_until_trending'] == 0: \n",
    "        return 0\n",
    "    elif row['days_until_trending'] == 1:\n",
    "        return 1\n",
    "    elif row['days_until_trending'] == 2:\n",
    "        return 2\n",
    "    elif row['days_until_trending'] <= 5:\n",
    "        return 3\n",
    "    else:\n",
    "        return 6\n",
    "\n",
    "df['target_category'] = df.apply(assign_target_category, axis=1)\n",
    "df['channel_title'] = df['channel_title'].astype('category')"
   ]
  },
  {
   "source": [
    "### Map tag factor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_df = pd.read_csv('../data/tags.csv')\n",
    "tag_df = tag_df.set_index('tag')\n",
    "def calculate_tag_factor(tag_string, tag_data):\n",
    "    tag_list = pd.Series(list(set(map(lambda x: x.strip('\\\"').lower(), tag_string.split('|')))))\n",
    "    return tag_list.apply(lambda tag: tag_data['factor'].get(tag, np.nan)).mean(skipna=True)\n",
    "    \n",
    "df['tag_factors'] = df['tags'].apply(lambda x: calculate_tag_factor(x, tag_df))\n",
    "df['tag_factors'] = df.apply(lambda row: 0 if np.isnan(row['tag_factors']) else row['tag_factors'], axis=1)"
   ]
  },
  {
   "source": [
    "### Remove unused columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df)\n",
    "dropColumns = ['video_id', 'title', 'tags', 'thumbnail_link', 'description']\n",
    "for column in df.columns:\n",
    "    numberOfUniqueValues = df[column].nunique()\n",
    "    if numberOfUniqueValues < 2:\n",
    "        dropColumns.append(column)\n",
    "    elif df[column].dtype == 'object' and numberOfUniqueValues > N * 0.9:\n",
    "        dropColumns.append(column)\n",
    "    elif df[column].isna().sum() / N > 0.95:\n",
    "        dropColumns.append(column)\n",
    "        \n",
    "df.drop(columns=dropColumns, inplace=True)"
   ]
  },
  {
   "source": [
    "## Encode features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = DataFrame(index=df.index)\n",
    "features = ['views', 'publish_hour']\n",
    "for feature in features:\n",
    "    feature_data = df[feature]\n",
    "    if df[feature].dtype.name == 'category':\n",
    "        x_label_encoder = preprocessing.LabelEncoder()\n",
    "        x_label_encoder.fit(feature_data.astype(str))\n",
    "        x_df[feature] = x_label_encoder.transform(feature_data)\n",
    "    elif df[feature].dtype.name == 'datetime64[ns]':\n",
    "        x_df[feature] = feature_data.to_seconds()\n",
    "    elif df[feature].dtype.name == 'bool':\n",
    "        x_df[feature] = int(feature_data)\n",
    "    else:\n",
    "        x_df[feature] = feature_data\n",
    "\n",
    "x = np.reshape(x_df, (-1, len(x_df.columns)))"
   ]
  },
  {
   "source": [
    "## Encode prediction target"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['target_category'].astype(str)\n",
    "y_label_encoder = preprocessing.LabelEncoder()\n",
    "y_label_encoder.fit(target)\n",
    "y = y_label_encoder.transform(target)"
   ]
  },
  {
   "source": [
    "## Create train and test datasubset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.40, random_state=0)"
   ]
  },
  {
   "source": [
    "## Declare classifiers\n",
    "\n",
    "```\n",
    "classifiers[:][0]: Name\n",
    "classifiers[:][1]: Classifier object\n",
    "classifiers[:][2]: Prediction\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "\n",
    "classifiers.append(['Decision Tree', DecisionTreeClassifier()])\n",
    "classifiers.append(['K Nearest Neighbor', KNeighborsClassifier(n_jobs=-1)])\n",
    "classifiers.append(['Random Forest', RandomForestClassifier(n_jobs=-1)])\n",
    "classifiers.append(['XG Boost', XGBClassifier(use_label_encoder=False, verbosity=0)])\n",
    "\n",
    "classifiers.append(['K Nearest Neighbor (optimised)', KNeighborsClassifier(n_jobs=-1, algorithm='ball_tree', leaf_size=20, n_neighbors=8, p=1, weights='uniform')])\n",
    "classifiers.append(['Random Forest (optimised)', RandomForestClassifier(n_jobs=-1, n_estimators=10, max_depth=2, min_samples_split=5)])\n",
    "classifiers.append(['XG Boost (optimised)', XGBClassifier(use_label_encoder=False, verbosity=0, n_estimators=50, max_depth=2)])"
   ]
  },
  {
   "source": [
    "## Train model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training - Decision Tree\n",
      "Wall time: 105 ms\n",
      "\n",
      "Training - K Nearest Neighbor\n",
      "Wall time: 150 ms\n",
      "\n",
      "Training - Random Forest\n",
      "Wall time: 879 ms\n",
      "\n",
      "Training - XG Boost\n",
      "Wall time: 8.03 s\n",
      "\n",
      "Training - K Nearest Neighbor (optimised)\n",
      "Wall time: 38.3 ms\n",
      "\n",
      "Training - Random Forest (optimised)\n",
      "Wall time: 85.7 ms\n",
      "\n",
      "Training - XG Boost (optimised)\n",
      "Wall time: 1.56 s\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    print('\\nTraining - ' + classifier[0])\n",
    "    %time classifier[1].fit(x_train, y_train)"
   ]
  },
  {
   "source": [
    "## Predict test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Predicting - Decision Tree\n",
      "Wall time: 11.6 ms\n",
      "\n",
      "Predicting - K Nearest Neighbor\n",
      "Wall time: 471 ms\n",
      "\n",
      "Predicting - Random Forest\n",
      "Wall time: 115 ms\n",
      "\n",
      "Predicting - XG Boost\n",
      "Wall time: 34 ms\n",
      "\n",
      "Predicting - K Nearest Neighbor (optimised)\n",
      "Wall time: 491 ms\n",
      "\n",
      "Predicting - Random Forest (optimised)\n",
      "Wall time: 17 ms\n",
      "\n",
      "Predicting - XG Boost (optimised)\n",
      "Wall time: 10 ms\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    print('\\nPredicting - ' + classifier[0])\n",
    "    %time classifier.append(classifier[1].predict(x_test))"
   ]
  },
  {
   "source": [
    "## Calculate accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nAccuracy - Decision Tree\n0.5325661116552399\n\nAccuracy - K Nearest Neighbor\n0.589128305582762\n\nAccuracy - Random Forest\n0.5377081292850147\n\nAccuracy - XG Boost\n0.6394466209598433\n\nAccuracy - K Nearest Neighbor (optimised)\n0.6012487757100882\n\nAccuracy - Random Forest (optimised)\n0.6275097943192948\n\nAccuracy - XG Boost (optimised)\n0.6480166503428012\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    print('\\nAccuracy - ' + classifier[0])\n",
    "    print(accuracy_score(y_test, classifier[2]))"
   ]
  },
  {
   "source": [
    "## Accuracy of baseline classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6237512242899118"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "len(df[df['target_category'] == 1]) / len(df)"
   ]
  }
 ]
}