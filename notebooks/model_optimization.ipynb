{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Predicion model optimization\n",
    "\n",
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "source": [
    "## Data preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/DEvideos.csv',\n",
    "    low_memory=False)\n",
    "\n",
    "df['trending_date'] = df.apply(lambda row: datetime.strptime(row['trending_date'], '%y.%d.%m'), axis=1)\n",
    "df['publish_time'] = df.apply(lambda row: datetime.strptime(row['publish_time'], '%Y-%m-%dT%H:%M:%S.000Z'), axis=1)\n",
    "df['days_until_trending'] = df.apply(lambda row: ((row['trending_date'] - row['publish_time']).days + 1), axis=1)\n",
    "\n",
    "df['tags_count'] = df.apply(lambda row: len(row['tags'].split('|')), axis=1)\n",
    "df['publish_hour'] = df['publish_time'].map(lambda x: x.hour)\n",
    "df['publish_month'] = df['publish_time'].map(lambda x: x.month)\n",
    "df['publish_year'] = df['publish_time'].map(lambda x: x.year)\n",
    "df['publish_day_of_month'] = df['publish_time'].map(lambda x: x.day)\n",
    "df['publish_weekday'] = df['publish_time'].map(lambda x: x.weekday()) # 0: Monday, 6: Sunday\n",
    "df['trending_weekday'] = df['trending_date'].map(lambda x: x.weekday()) # 0: Monday, 6: Sunday\n",
    "\n",
    "df['like_dislike_ratio'] = df.apply(lambda row: row['likes'] / (row['dislikes'] + 1), axis=1)\n",
    "df['like_view_ratio'] = df.apply(lambda row: row['likes'] / (row['views'] + 1), axis=1)\n",
    "\n",
    "df['ratings'] = df['likes'] + df['dislikes']\n",
    "df['likes_per_rating'] = df['likes'] / df['ratings']\n",
    "df['ratings_per_view'] = df['ratings'] / df['views']\n",
    "df['comments_per_view'] = df['comment_count'] / df['views']\n",
    "\n",
    "# Using int instead of cat\n",
    "def assign_target_category(row):\n",
    "    if row['days_until_trending'] == 0: \n",
    "        return 0\n",
    "    elif row['days_until_trending'] == 1:\n",
    "        return 1\n",
    "    elif row['days_until_trending'] == 2:\n",
    "        return 2\n",
    "    elif row['days_until_trending'] <= 5:\n",
    "        return 3\n",
    "    else:\n",
    "        return 6\n",
    "\n",
    "df['target_category'] = df.apply(assign_target_category, axis=1)\n",
    "\n",
    "N = len(df)\n",
    "dropColumns = ['video_id', 'title', 'tags', 'thumbnail_link', 'description']\n",
    "for column in df.columns:\n",
    "    numberOfUniqueValues = df[column].nunique()\n",
    "    if numberOfUniqueValues < 2:\n",
    "        dropColumns.append(column)\n",
    "    elif df[column].dtype == 'object' and numberOfUniqueValues > N * 0.9:\n",
    "        dropColumns.append(column)\n",
    "    elif df[column].isna().sum() / N > 0.95:\n",
    "        dropColumns.append(column)\n",
    "        \n",
    "df.drop(columns=dropColumns, inplace=True)\n",
    "\n",
    "df['channel_title'] = df['channel_title'].astype('category')"
   ]
  },
  {
   "source": [
    "## Encode features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = DataFrame(index=df.index)\n",
    "features = ['publish_weekday', 'publish_month']\n",
    "for feature in features:\n",
    "    feature_data = df[feature]\n",
    "    if df[feature].dtype.name == 'category':\n",
    "        x_label_encoder = preprocessing.LabelEncoder()\n",
    "        x_label_encoder.fit(feature_data.astype(str))\n",
    "        x_df[feature] = x_label_encoder.transform(feature_data)\n",
    "    elif df[feature].dtype.name == 'datetime64[ns]':\n",
    "        x_df[feature] = feature_data.to_seconds()\n",
    "    elif df[feature].dtype.name == 'bool':\n",
    "        x_df[feature] = int(feature_data)\n",
    "    else:\n",
    "        x_df[feature] = feature_data\n",
    "\n",
    "x = np.reshape(x_df, (-1, len(x_df.columns)))"
   ]
  },
  {
   "source": [
    "## Encode prediction target"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['target_category'].astype(str)\n",
    "y_label_encoder = preprocessing.LabelEncoder()\n",
    "y_label_encoder.fit(target)\n",
    "y = y_label_encoder.transform(target)"
   ]
  },
  {
   "source": [
    "## Calculate best prediction parameters\n",
    "\n",
    "### XGBoost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_model = XGBClassifier(use_label_encoder=False)\n",
    "optimization_dict = {'max_depth': [2,4,8,16,32,64,None],\n",
    "                     'n_estimators': [10,20,40,80,160,320]}\n",
    "\n",
    "model = GridSearchCV(xgb_model, optimization_dict, \n",
    "                     scoring='accuracy')\n",
    "\n",
    "model.fit(x,y)\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)"
   ]
  },
  {
   "source": [
    "### K Nearest Neighbors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6237512242899118\n{'n_neighbors': 2048}\nCPU times: user 1min 41s, sys: 1.61 s, total: 1min 43s\nWall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn_model = KNeighborsClassifier()\n",
    "optimization_dict = {'n_neighbors': [2,4,8,16,32,64,128,256,512,1024,2048]}\n",
    "\n",
    "model = GridSearchCV(knn_model, optimization_dict, \n",
    "                     scoring='accuracy')\n",
    "\n",
    "model.fit(x,y)\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)"
   ]
  },
  {
   "source": [
    "### Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5701028403525955\n{'max_depth': 2, 'min_samples_split': 5, 'n_estimators': 10}\nCPU times: user 5min 46s, sys: 667 ms, total: 5min 47s\nWall time: 5min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_model = RandomForestClassifier()\n",
    "optimization_dict = {'max_depth': [2,4,8,16,32,64,None],\n",
    "                     'n_estimators': [10,20,40,80,160,320],\n",
    "                     'min_samples_split': [5, 10]}\n",
    "\n",
    "model = GridSearchCV(rf_model, optimization_dict, \n",
    "                     scoring='accuracy')\n",
    "\n",
    "model.fit(x,y)\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)"
   ]
  }
 ]
}