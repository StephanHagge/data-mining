{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "341fe68f31b2607f2567ea4631bf318bef91dbbea98de31e2266395fcf799846"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data prediction\n",
    "\n",
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "source": [
    "## Data preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../0_data/DEvideos.csv',\n",
    "    low_memory=False)\n",
    "\n",
    "df['trending_date'] = df.apply(lambda row: datetime.strptime(row['trending_date'], '%y.%d.%m'), axis=1)\n",
    "df['publish_time'] = df.apply(lambda row: datetime.strptime(row['publish_time'], '%Y-%m-%dT%H:%M:%S.000Z'), axis=1)\n",
    "df['days_until_trending'] = df.apply(lambda row: ((row['trending_date'] - row['publish_time']).days + 1), axis=1)\n",
    "\n",
    "df['tags_count'] = df.apply(lambda row: len(row['tags'].split('|')), axis=1)\n",
    "df['publish_hour'] = df['publish_time'].map(lambda x: x.hour)\n",
    "df['publish_month'] = df['publish_time'].map(lambda x: x.month)\n",
    "df['publish_year'] = df['publish_time'].map(lambda x: x.year)\n",
    "df['publish_day_of_month'] = df['publish_time'].map(lambda x: x.day)\n",
    "df['publish_weekday'] = df['publish_time'].map(lambda x: x.weekday()) # 0: Monday, 6: Sunday\n",
    "\n",
    "df['like_dislike_ratio'] = df.apply(lambda row: row['likes'] / (row['dislikes'] + 1), axis=1)\n",
    "df['like_view_ratio'] = df.apply(lambda row: row['likes'] / (row['views'] + 1), axis=1)\n",
    "\n",
    "df['ratings'] = df['likes'] + df['dislikes']\n",
    "df['likes_per_rating'] = df.apply(lambda row: 0 if row['ratings'] == 0 else row['likes'] / row['ratings'], axis=1)\n",
    "df['ratings_per_view'] = df['ratings'] / df['views']\n",
    "df['comments_per_view'] = df['comment_count'] / df['views']\n",
    "\n",
    "# Using int instead of cat\n",
    "def assign_target_category(row):\n",
    "    if row['days_until_trending'] == 0: \n",
    "        return 0\n",
    "    elif row['days_until_trending'] == 1:\n",
    "        return 1\n",
    "    elif row['days_until_trending'] == 2:\n",
    "        return 2\n",
    "    elif row['days_until_trending'] <= 5:\n",
    "        return 3\n",
    "    else:\n",
    "        return 6\n",
    "\n",
    "df['target_category'] = df.apply(assign_target_category, axis=1)\n",
    "df['channel_title'] = df['channel_title'].astype('category')"
   ]
  },
  {
   "source": [
    "### Map tag factor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_df = pd.read_csv('../0_data/tags.csv')\n",
    "tag_df = tag_df.set_index('tag')\n",
    "def calculate_tag_factor(tag_string, tag_data):\n",
    "    tag_list = pd.Series(list(set(map(lambda x: x.strip('\\\"').lower(), tag_string.split('|')))))\n",
    "    return tag_list.apply(lambda tag: tag_data['factor'].get(tag, np.nan)).mean(skipna=True)\n",
    "    \n",
    "df['tag_factors'] = df['tags'].apply(lambda x: calculate_tag_factor(x, tag_df))\n",
    "df['tag_factors'] = df.apply(lambda row: 0 if np.isnan(row['tag_factors']) else row['tag_factors'], axis=1)"
   ]
  },
  {
   "source": [
    "### Remove unused columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df)\n",
    "dropColumns = ['video_id', 'title', 'tags', 'thumbnail_link', 'description']\n",
    "for column in df.columns:\n",
    "    numberOfUniqueValues = df[column].nunique()\n",
    "    if numberOfUniqueValues < 2:\n",
    "        dropColumns.append(column)\n",
    "    elif df[column].dtype == 'object' and numberOfUniqueValues > N * 0.9:\n",
    "        dropColumns.append(column)\n",
    "    elif df[column].isna().sum() / N > 0.95:\n",
    "        dropColumns.append(column)\n",
    "        \n",
    "df.drop(columns=dropColumns, inplace=True)"
   ]
  },
  {
   "source": [
    "## Encode features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = DataFrame(index=df.index)\n",
    "features = ['views', 'publish_hour', 'ratings_per_view', 'comments_per_view', 'tag_factors']\n",
    "for feature in features:\n",
    "    feature_data = df[feature]\n",
    "    if df[feature].dtype.name == 'category':\n",
    "        x_label_encoder = preprocessing.LabelEncoder()\n",
    "        x_label_encoder.fit(feature_data.astype(str))\n",
    "        x_df[feature] = x_label_encoder.transform(feature_data)\n",
    "    elif df[feature].dtype.name == 'datetime64[ns]':\n",
    "        x_df[feature] = feature_data.to_seconds()\n",
    "    elif df[feature].dtype.name == 'bool':\n",
    "        x_df[feature] = int(feature_data)\n",
    "    else:\n",
    "        x_df[feature] = feature_data\n",
    "\n",
    "x = np.reshape(x_df, (-1, len(x_df.columns)))"
   ]
  },
  {
   "source": [
    "## Encode prediction target"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['target_category'].astype(str)\n",
    "y_label_encoder = preprocessing.LabelEncoder()\n",
    "y_label_encoder.fit(target)\n",
    "y = y_label_encoder.transform(target)"
   ]
  },
  {
   "source": [
    "## Create train and test datasubset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.40, random_state=0)"
   ]
  },
  {
   "source": [
    "## Declare classifiers\n",
    "\n",
    "```\n",
    "classifiers[:][0]: Name\n",
    "classifiers[:][1]: Classifier object\n",
    "classifiers[:][2]: Prediction\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "\n",
    "classifiers.append(['Decision Tree', DecisionTreeClassifier()])\n",
    "classifiers.append(['K Nearest Neighbor', KNeighborsClassifier(n_jobs=-1)])\n",
    "classifiers.append(['Random Forest', RandomForestClassifier(n_jobs=-1)])\n",
    "classifiers.append(['XG Boost', XGBClassifier(use_label_encoder=False, verbosity=0)])\n",
    "\n",
    "classifiers.append(['Decision Tree (optimized)', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None, max_features=None, max_leaf_nodes=50, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, splitter='best')])\n",
    "classifiers.append(['K Nearest Neighbor (optimized)', KNeighborsClassifier(n_jobs=-1, algorithm='kd_tree', leaf_size=20, n_neighbors=8, p=1, weights='uniform')])\n",
    "classifiers.append(['Random Forest (optimized)', RandomForestClassifier(n_jobs=-1, class_weight=None, criterion='gini', max_depth=9, max_features='log2', max_leaf_nodes=None, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=4, min_weight_fraction_leaf=0.0, n_estimators=200)])\n",
    "classifiers.append(['XG Boost (optimized)', XGBClassifier(use_label_encoder=False, verbosity=0, booster='gbtree', colsample_bylevel=0.75, colsample_bynode=1, colsample_bytree=1, gamma=2, learning_rate=0.5, max_delta_step=0, max_depth=6, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=0, subsample=1, tree_method='hist')])"
   ]
  },
  {
   "source": [
    "## Train model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training - Decision Tree\n",
      "Wall time: 142 ms\n",
      "\n",
      "Training - K Nearest Neighbor\n",
      "Wall time: 44 ms\n",
      "\n",
      "Training - Random Forest\n",
      "Wall time: 467 ms\n",
      "\n",
      "Training - XG Boost\n",
      "Wall time: 3.57 s\n",
      "\n",
      "Training - Decision Tree (optimized)\n",
      "Wall time: 70 ms\n",
      "\n",
      "Training - K Nearest Neighbor (optimized)\n",
      "Wall time: 41 ms\n",
      "\n",
      "Training - Random Forest (optimized)\n",
      "Wall time: 603 ms\n",
      "\n",
      "Training - XG Boost (optimized)\n",
      "Wall time: 864 ms\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    print('\\nTraining - ' + classifier[0])\n",
    "    %time classifier[1].fit(x_train, y_train)"
   ]
  },
  {
   "source": [
    "## Predict test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Predicting - Decision Tree\n",
      "Wall time: 5 ms\n",
      "\n",
      "Predicting - K Nearest Neighbor\n",
      "Wall time: 302 ms\n",
      "\n",
      "Predicting - Random Forest\n",
      "Wall time: 46 ms\n",
      "\n",
      "Predicting - XG Boost\n",
      "Wall time: 22 ms\n",
      "\n",
      "Predicting - Decision Tree (optimized)\n",
      "Wall time: 2 ms\n",
      "\n",
      "Predicting - K Nearest Neighbor (optimized)\n",
      "Wall time: 320 ms\n",
      "\n",
      "Predicting - Random Forest (optimized)\n",
      "Wall time: 77 ms\n",
      "\n",
      "Predicting - XG Boost (optimized)\n",
      "Wall time: 14 ms\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    print('\\nPredicting - ' + classifier[0])\n",
    "    %time classifier.append(classifier[1].predict(x_test))"
   ]
  },
  {
   "source": [
    "## Calculate accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nAccuracy - Decision Tree\n0.6003305582761999\n\nAccuracy - K Nearest Neighbor\n0.5890058765915769\n\nAccuracy - Random Forest\n0.682664054848188\n\nAccuracy - XG Boost\n0.6765426052889324\n\nAccuracy - Decision Tree (optimized)\n0.6575048971596474\n\nAccuracy - K Nearest Neighbor (optimized)\n0.6013099902056807\n\nAccuracy - Random Forest (optimized)\n0.6771547502448579\n\nAccuracy - XG Boost (optimized)\n0.6783178256611165\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    print('\\nAccuracy - ' + classifier[0])\n",
    "    print(accuracy_score(y_test, classifier[2]))"
   ]
  },
  {
   "source": [
    "## Accuracy of baseline classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6237512242899118"
      ]
     },
     "metadata": {},
     "execution_count": 194
    }
   ],
   "source": [
    "len(df[df['target_category'] == 1]) / len(df)"
   ]
  }
 ]
}